{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhang8yiming/ML-DL/blob/main/L3_Homework_Reference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8b9d6583-6ae1-4bb6-970c-c80d42dfebdb",
        "_uuid": "d56b7961b91d7f67554ec48bd1d2485fb7419120",
        "id": "HlvL5ePdqUjD"
      },
      "source": [
        "# About the dataset\n",
        "This contains data of news headlines published over a period of 15 years. From the reputable Australian news source ABC (Australian Broadcasting Corp.)\n",
        "Site: http://www.abc.net.au/\n",
        "Prepared by Rohit Kulkarni\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "moA_Sy-gqUjF"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction import text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "scrolled": true,
        "id": "Z0Q4JcaxqUjG",
        "outputId": "ac12f34b-eefd-46c7-fec7-cd717b9846d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       headline_text\n",
              "0  aba decides against community broadcasting lic...\n",
              "1     act fire witnesses must be aware of defamation\n",
              "2     a g calls for infrastructure protection summit\n",
              "3           air nz staff in aust strike for pay rise\n",
              "4      air nz strike to affect australian travellers"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"../input/abcnews-date-text.csv\",error_bad_lines=False,usecols =[\"headline_text\"])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVW97NfXqUjG"
      },
      "outputs": [],
      "source": [
        "data.to_csv('abcnews.csv', index=False, encoding='utf8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3e44d856-a323-45ac-b7cc-80d77385060f",
        "_uuid": "a498ee778ab763e0801b8f9cf14e1d4d01f38846",
        "id": "QCVH7XU7qUjG",
        "outputId": "17e8bef8-b620-4eab-e1ca-1accd8a057ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1226258 entries, 0 to 1226257\n",
            "Data columns (total 1 columns):\n",
            "headline_text    1226258 non-null object\n",
            "dtypes: object(1)\n",
            "memory usage: 9.4+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ff887c6d-0470-4f62-860b-9457b223bb8c",
        "_uuid": "eb590852f097f66ea53be9a970789430fc3f6a63",
        "id": "_Nsollr8qUjH"
      },
      "source": [
        "# Deleting dupliate headlines(if any)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42392880-315c-41bf-98e8-a1cbfab72f6e",
        "_uuid": "1e0143660cbb59acf14ed07c847fd9bc3ca85045",
        "collapsed": true,
        "id": "KSWnS1qjqUjH"
      },
      "outputs": [],
      "source": [
        "data[data['headline_text'].duplicated(keep=False)].sort_values('headline_text').head(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9f5ff611-397e-45b7-9616-7bc33f6e81bb",
        "_uuid": "4e5e82d7c6fb0e7b14f8b5772bea14e448f88fcc",
        "collapsed": true,
        "id": "HK-AMF9SqUjH"
      },
      "outputs": [],
      "source": [
        "data = data.drop_duplicates('headline_text')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f1bb8d35-27aa-4ff4-9a39-4329517aa6a4",
        "_uuid": "f022fdf6441499ed52b34c063240f4f28b2ff3a5",
        "id": "7V_F59PCqUjH"
      },
      "source": [
        "# NLP "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7ecba7c7-84d0-426b-aa9c-9ca05d45da75",
        "_uuid": "d2f1e1b88fb7b29fd47c249be3af044ef1e2a246",
        "id": "vDz3w5FIqUjI"
      },
      "source": [
        "# Preparing data for vectorizaion\n",
        "However, when doing natural language processing, words must be converted into vectors that machine learning algorithms can make use of. If your goal is to do machine learning on text data, like movie reviews or tweets or anything else, you need to convert the text data into numbers. This process is sometimes referred to as “embedding” or “vectorization”.\n",
        "\n",
        "In terms of vectorization, it is important to remember that it isn’t merely turning a single word into a single number. While words can be transformed into numbers, an entire document can be translated into a vector. Not only can a vector have more than one dimension, but with text data vectors are usually high-dimensional. This is because each dimension of your feature data will correspond to a word, and the language in the documents you are examining will have thousands of words.\n",
        "\n",
        "# TF-IDF\n",
        "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf-idf value increases proportionally to the number of times a word appears in the document and is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general. Nowadays, tf-idf is one of the most popular term-weighting schemes; 83% of text-based recommender systems in the domain of digital libraries use tf-idf.\n",
        "\n",
        "Variations of the tf–idf weighting scheme are often used by search engines as a central tool in scoring and ranking a document's relevance given a user query. tf–idf can be successfully used for stop-words filtering in various subject fields, including text summarization and classification.\n",
        "\n",
        "One of the simplest ranking functions is computed by summing the tf–idf for each query term; many more sophisticated ranking functions are variants of this simple model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c7e595ab-440c-4ad7-98e4-4358cc724d8c",
        "_uuid": "9c1c23ecabae8217a9aa8f90371f2a30053cc6f1",
        "collapsed": true,
        "id": "JQmMoIfBqUjI"
      },
      "outputs": [],
      "source": [
        "punc = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}',\"%\"]\n",
        "stop_words = text.ENGLISH_STOP_WORDS.union(punc)\n",
        "desc = data['headline_text'].values\n",
        "vectorizer = TfidfVectorizer(stop_words = stop_words)\n",
        "X = vectorizer.fit_transform(desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb56971e-5412-4138-a4cd-0e14844796be",
        "_uuid": "10af64e15e2f08c30da71b847432eedc2aece199",
        "collapsed": true,
        "id": "uHATgCfMqUjJ"
      },
      "outputs": [],
      "source": [
        "word_features = vectorizer.get_feature_names()\n",
        "print(len(word_features))\n",
        "print(word_features[5000:5100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "871b1bd6-c411-4ff6-a784-9b376a0db4e6",
        "_uuid": "e480f5b88938660f05c09f75af5f9f58d7110096",
        "id": "Z4J-KlA1qUjJ"
      },
      "source": [
        "# Stemming\n",
        "Stemming is the process of reducing a word into its stem, i.e. its root form. The root form is not necessarily a word by itself, but it can be used to generate words by concatenating the right suffix. For example, the words fish, fishes and fishing all stem into fish, which is a correct word. On the other side, the words study, studies and studying stems into studi, which is not an English word.\n",
        "\n",
        "# Tokenizing\n",
        "Tokenization is breaking the sentence into words and punctuation,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "536a1a88-48a3-43d0-b368-ccf31947e5b1",
        "_uuid": "5d25104db183624b990a1d64e10cc618fd8ee715",
        "collapsed": true,
        "id": "8PZUqrg4qUjJ"
      },
      "outputs": [],
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "tokenizer = RegexpTokenizer(r'[a-zA-Z\\']+')\n",
        "\n",
        "def tokenize(text):\n",
        "    return [stemmer.stem(word) for word in tokenizer.tokenize(text.lower())]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9877cf33-ebe8-46e4-b26e-c6f673617517",
        "_uuid": "d190c4d6b9cb52ad70a021e3475704538b47f85f",
        "id": "blviT-ZmqUjJ"
      },
      "source": [
        "# Vectorization with stop words(words irrelevant to the model), stemming and tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "18e1d30c-5515-4c0d-89e4-6af99658bee3",
        "_uuid": "5fcc93fa3093f30d181ffa38b4ca46b133316952",
        "collapsed": true,
        "scrolled": false,
        "id": "a2LNmJ4KqUjJ"
      },
      "outputs": [],
      "source": [
        "vectorizer2 = TfidfVectorizer(stop_words = stop_words, tokenizer = tokenize)\n",
        "X2 = vectorizer2.fit_transform(desc)\n",
        "word_features2 = vectorizer2.get_feature_names()\n",
        "print(len(word_features2))\n",
        "print(word_features2[:50]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "acdc11f4-7b5c-4aee-8c42-1a752bffbc2e",
        "_uuid": "244a3015e5b4f4f84c174586fa875f5cf49cff1d",
        "collapsed": true,
        "id": "a1sT6BoyqUjJ"
      },
      "outputs": [],
      "source": [
        "vectorizer3 = TfidfVectorizer(stop_words = stop_words, tokenizer = tokenize, max_features = 1000)\n",
        "X3 = vectorizer3.fit_transform(desc)\n",
        "words = vectorizer3.get_feature_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e8a8c1ed-8970-49e0-bae5-0e0d85abea84",
        "_uuid": "b5f2e66c25d17527b78ae1a1fe174f1ac6310286",
        "id": "zgymNDqYqUjK"
      },
      "source": [
        "For this, we will use k-means clustering algorithm.\n",
        "# K-means clustering\n",
        "(Source [Wikipedia](https://en.wikipedia.org/wiki/K-means_clustering#Standard_algorithm) )\n",
        "![http://gdurl.com/5BbP](http://gdurl.com/5BbP)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c9a1312e-45f7-44e4-9407-13012bdf97ce",
        "_uuid": "39ba3fa0f53454111495da2f7e7719572afec93a",
        "id": "XYQBb4SEqUjK"
      },
      "source": [
        "# Elbow method to select number of clusters\n",
        "This method looks at the percentage of variance explained as a function of the number of clusters: One should choose a number of clusters so that adding another cluster doesn't give much better modeling of the data. More precisely, if one plots the percentage of variance explained by the clusters against the number of clusters, the first clusters will add much information (explain a lot of variance), but at some point the marginal gain will drop, giving an angle in the graph. The number of clusters is chosen at this point, hence the \"elbow criterion\". This \"elbow\" cannot always be unambiguously identified. Percentage of variance explained is the ratio of the between-group variance to the total variance, also known as an F-test. A slight variation of this method plots the curvature of the within group variance.\n",
        "# Basically, number of clusters = the x-axis value of the point that is the corner of the \"elbow\"(the plot looks often looks like an elbow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c72b26ab-4bef-44e6-b854-5bca3cd1f217",
        "_uuid": "992bea80b2647c4f4e564bb020ce8eab07db6b78",
        "collapsed": true,
        "scrolled": true,
        "id": "T_VlCps0qUjK"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(1,11):\n",
        "    kmeans = KMeans(n_clusters=i,init='k-means++',max_iter=300,n_init=10,random_state=0)\n",
        "    kmeans.fit(X3)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "plt.plot(range(1,11),wcss)\n",
        "plt.title('The Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.savefig('elbow.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2dd63611-35d6-4c6e-b076-c10e18a3b10c",
        "_uuid": "d5184cf4e47df719970d89c5ea8e15d4b9eaa1e5",
        "id": "_5BwsI-FqUjK"
      },
      "source": [
        "As more than one elbows have been generated, I will have to select right amount of clusters by trial and error. So, I will showcase the results of different amount of clusters to find out the right amount of clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e096b262-a06c-4f0a-9c50-2ef4bda9b926",
        "_uuid": "0ed982322b3a0fecb997e88ef0fb2f681c5a801c",
        "collapsed": true,
        "scrolled": false,
        "id": "aJgOi6YBqUjK"
      },
      "outputs": [],
      "source": [
        "print(words[250:300])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0ca23daa-681a-4cb8-93ae-d2d2ac137604",
        "_uuid": "f463135cb544f6ffa999861c7bf049cbbede8fe6",
        "id": "332_nFMfqUjK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a3c414e5-70b2-4c63-a46a-f9c82e406e4b",
        "_uuid": "6992f369b10d54adf27ecdcf24c6f57deabf466f",
        "id": "4NEydFEoqUjK"
      },
      "source": [
        "# 3 Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b395dddc-8acb-40a8-825e-a6f3a615809e",
        "_uuid": "e0e187a022ec9032385f715d87cfbb865a11698d",
        "collapsed": true,
        "scrolled": false,
        "id": "Au6NPtAFqUjK"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters = 3, n_init = 20, n_jobs = 1) # n_init(number of iterations for clsutering) n_jobs(number of cpu cores to use)\n",
        "kmeans.fit(X3)\n",
        "# We look at 3 the clusters generated by k-means.\n",
        "common_words = kmeans.cluster_centers_.argsort()[:,-1:-26:-1]\n",
        "for num, centroid in enumerate(common_words):\n",
        "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "05f80701-83af-49c1-a7b8-df8c20396bb9",
        "_uuid": "4750051c6cbdc6d262f31a94f5c4776eb020644a",
        "id": "vN8HO1j9qUjK"
      },
      "source": [
        "# 5 Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "137b7e2c-970f-4f2f-929e-c7b2bd2a8004",
        "_uuid": "2813cee7e61b966b179b806d29b222c55551ee35",
        "collapsed": true,
        "scrolled": false,
        "id": "zm_iMMliqUjK"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters = 5, n_init = 20, n_jobs = 1)\n",
        "kmeans.fit(X3)\n",
        "# We look at 5 the clusters generated by k-means.\n",
        "common_words = kmeans.cluster_centers_.argsort()[:,-1:-26:-1]\n",
        "for num, centroid in enumerate(common_words):\n",
        "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e5ab0cdc-1178-486d-a982-3457aa69d234",
        "_uuid": "4faeeea430f9f679a594b2c7f1ef1c857611ade5",
        "id": "24VNqicwqUjK"
      },
      "source": [
        "# 6 Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "de4d9fbb-2462-4491-899f-b1e28e1a7697",
        "_uuid": "73c1c5bfafe12fd9bd57ab0c3bd07f60630f05a8",
        "collapsed": true,
        "id": "z4Nwlr5PqUjK"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters = 6, n_init = 20, n_jobs = 1)\n",
        "kmeans.fit(X3)\n",
        "# We look at 6 the clusters generated by k-means.\n",
        "common_words = kmeans.cluster_centers_.argsort()[:,-1:-26:-1]\n",
        "for num, centroid in enumerate(common_words):\n",
        "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bff92434-ec9d-4e6b-a4a2-72ec4ea6f3bc",
        "_uuid": "7225da580975f8589615a8fd5232ba3c80780845",
        "id": "S8UtVwScqUjK"
      },
      "source": [
        "# 8 Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4134a6d2-09aa-4cf5-9821-d95d0482c4ac",
        "_uuid": "cf3c5af56aa05f6679effe85774207fe824255a1",
        "collapsed": true,
        "id": "TRuIpSM5qUjL"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters = 8, n_init = 20, n_jobs = 1)\n",
        "kmeans.fit(X3)\n",
        "# Finally, we look at 8 the clusters generated by k-means.\n",
        "common_words = kmeans.cluster_centers_.argsort()[:,-1:-26:-1]\n",
        "for num, centroid in enumerate(common_words):\n",
        "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a168498b-1322-4010-b462-596bc0ba186b",
        "_uuid": "4717568e34623b3b88f033670c20f01f7ddd63a6",
        "id": "kzCEFcYNqUjL"
      },
      "source": [
        "Because even I didn't know what kind of clusters would be generated, I will describe them in comments."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "L3_Homework_Reference.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}