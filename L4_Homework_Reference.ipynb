{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhang8yiming/ML-DL/blob/main/L4_Homework_Reference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B8plGllfJkl"
      },
      "source": [
        "# 集成学习  \n",
        "\n",
        "集成学习是一种机器学习范式，通过训练多个模型来解决同一问题。下面将使用决策树以及其集成版本对经典数据集 MNIST 建模，观察不同集成方法的差异。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmE-4ZgIfJkn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPVy6s96fJko"
      },
      "source": [
        "## 构建数据集\n",
        "\n",
        "此次使用的 Mnist 数据集并非原始的格式，为了更加方便的适配本次训练，将原始数据集中 28 * 28 的图片进行了 [flatten](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flatten.html) 操作，变成了 784 个特征，下方 DataFrame 中的列：1x1, 1x2, ..., 28x28，表示图片中第 *i* 行、第 *j* 列的像素值，由于是灰度图，所以像素值只有 0 和 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuBuqF4mfJko",
        "outputId": "66c36b3e-a4eb-43e0-a40e-cf3801924a7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>1x1</th>\n",
              "      <th>1x2</th>\n",
              "      <th>1x3</th>\n",
              "      <th>1x4</th>\n",
              "      <th>1x5</th>\n",
              "      <th>1x6</th>\n",
              "      <th>1x7</th>\n",
              "      <th>1x8</th>\n",
              "      <th>1x9</th>\n",
              "      <th>...</th>\n",
              "      <th>28x19</th>\n",
              "      <th>28x20</th>\n",
              "      <th>28x21</th>\n",
              "      <th>28x22</th>\n",
              "      <th>28x23</th>\n",
              "      <th>28x24</th>\n",
              "      <th>28x25</th>\n",
              "      <th>28x26</th>\n",
              "      <th>28x27</th>\n",
              "      <th>28x28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
              "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "\n",
              "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
              "0      0      0      0      0      0      0      0      0  \n",
              "1      0      0      0      0      0      0      0      0  \n",
              "2      0      0      0      0      0      0      0      0  \n",
              "3      0      0      0      0      0      0      0      0  \n",
              "4      0      0      0      0      0      0      0      0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = df = pd.read_csv('mnist_train.csv')\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKDSibxrfJkp",
        "outputId": "2d750f02-207c-44bf-ac37-1f89219b119a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 60000 entries, 0 to 59999\n",
            "Columns: 785 entries, label to 28x28\n",
            "dtypes: int64(785)\n",
            "memory usage: 359.3 MB\n"
          ]
        }
      ],
      "source": [
        "# 查看训练数据信息:，有无 NaN，共有多少条数据 ...\n",
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTPFPS4ffJkp",
        "outputId": "091f852d-b1e8-4678-fa08-43207498605f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>1x1</th>\n",
              "      <th>1x2</th>\n",
              "      <th>1x3</th>\n",
              "      <th>1x4</th>\n",
              "      <th>1x5</th>\n",
              "      <th>1x6</th>\n",
              "      <th>1x7</th>\n",
              "      <th>1x8</th>\n",
              "      <th>1x9</th>\n",
              "      <th>...</th>\n",
              "      <th>28x19</th>\n",
              "      <th>28x20</th>\n",
              "      <th>28x21</th>\n",
              "      <th>28x22</th>\n",
              "      <th>28x23</th>\n",
              "      <th>28x24</th>\n",
              "      <th>28x25</th>\n",
              "      <th>28x26</th>\n",
              "      <th>28x27</th>\n",
              "      <th>28x28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
              "0      7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "1      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "2      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "3      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "4      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
              "\n",
              "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
              "0      0      0      0      0      0      0      0      0  \n",
              "1      0      0      0      0      0      0      0      0  \n",
              "2      0      0      0      0      0      0      0      0  \n",
              "3      0      0      0      0      0      0      0      0  \n",
              "4      0      0      0      0      0      0      0      0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 查看测试数据信息:，有无 NaN，共有多少条数据 ...\n",
        "test_df = df = pd.read_csv('mnist_test.csv')\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE5bTdXTfJkq",
        "outputId": "7eb5716d-4f1c-4a73-bf43-9eca45006dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Columns: 785 entries, label to 28x28\n",
            "dtypes: int64(785)\n",
            "memory usage: 59.9 MB\n"
          ]
        }
      ],
      "source": [
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVOJABfsfJkq",
        "outputId": "41b63a18-8978-4758-9b28-56cbb4b0f002"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(((60000, 784), (60000,)), ((10000, 784), (10000,)))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 构建训练、测试数据\n",
        "\n",
        "X_train = train_df.iloc[:, 1:]\n",
        "y_train = train_df.iloc[:, 0]\n",
        "\n",
        "X_test = test_df.iloc[:, 1:]\n",
        "y_test = test_df.iloc[:, 0]\n",
        "\n",
        "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91iU0dhBfJkq"
      },
      "source": [
        "## 决策树\n",
        "\n",
        "首先训练一个简单的决策树看看表现如何"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6G1xgJqfJkr",
        "outputId": "5891d088-f85c-43db-b927-ec51f655e3fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcTaBiDSfJkr",
        "outputId": "c15dbd05-2086-48b1-b2bf-61447a0cd926"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtc.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K24zBXffJkr",
        "outputId": "3b461b85-2bb4-4c34-d8a2-6c5ddc4eb933"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8763"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j9iFSOGfJks"
      },
      "source": [
        "> 从上面的训练集准确度和测试集的准确度来看，默认参数的决策树已经发生了过拟合，下面对 sklearn 提供的决策树 api 中的参数进行适当的调节，看看会有什么变化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu9pbEVcfJks",
        "outputId": "31f02826-b652-4965-adf5-32f3552dd495"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(min_samples_leaf=8)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtc = DecisionTreeClassifier(min_samples_leaf=8)\n",
        "dtc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0rEDDUffJks",
        "outputId": "def05808-b592-417e-d0af-dc0faedc0461"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9311333333333334, 0.8804)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtc.score(X_train, y_train), dtc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxiD_TZzfJks"
      },
      "source": [
        "> 从上面的结果看出，通过对参数 `min_samples_leaf` 的调整，过拟合的情况已经有所缓解，那这个参数是什么意思呢？为什么增大它可以缓解过拟合问题？`min_samples_leaf` 的含义是决策树中叶子结点所包含的最少的样本数量，通过增大这个参数，可以让决策树在训练的时候无法去捕捉训练数据任何一个细微的特征，导致对训练数据过拟合；叶子结点的样本数量大，也可以起到一定的投票作用，增强模型的泛化性能。可以尝试继续增大该参数的值，试着找到最佳的参数。除了这个参数还可以尝试调节 `min_samples_split`、`max_features` 等参数，具体的含义可以参考 [sklearn 文档](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXhuxkiNfJkt"
      },
      "source": [
        "## 随机森林\n",
        "\n",
        "看看决策树的 bagging 版本 随机森林的表现如何吧！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMWR3K2ifJkt",
        "outputId": "7a852c72-ec86-4c2c-9455-36fbb1bcc05b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=10)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfc = RandomForestClassifier(n_estimators=10)\n",
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq5Vbz-nfJkt",
        "outputId": "474aebb0-bdbe-4b30-c39b-e240a6be5579"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9990333333333333"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfc.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipcRfT3YfJkt",
        "outputId": "c03dac42-dad8-4368-90b1-650c4897a8c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9498"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pguLENSfJkt"
      },
      "source": [
        "> 不愧是集成版本，基本在默认参数下就达到了较好的性能，测试集准确度高出普通决策树 7 个百分点左右，但是对比训练、测试结果可以发现，仍然存在一定的过拟合情况，下面调整一些参数试试"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slhpX3vyfJku",
        "outputId": "b0af9b38-9afd-4737-bda5-5c6f04c01fce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=20)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfc = RandomForestClassifier(n_estimators=20)\n",
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVIza_ZYfJku",
        "outputId": "93ffa5ef-1f0b-4de5-a9af-5dc6088415e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9999, 0.9598)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfc.score(X_train, y_train), rfc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqsbVcZ5fJku"
      },
      "source": [
        "> 在增大了参数 `n_estimators` 之后，测试集准确度提升了 1 个百分点左右，这个参数的含义是同时训练 20 个决策树，最后对结果进行集成，这个参数的增加可以简单的认为是投票的人数增加了，那么最后的结果必然也会更加鲁棒。可以尝试继续增大这个参数，或者调节其他参数如 `max_samples`，适当少于全部训练数据量，可以增加不同子模型之间的差异，进一步提升泛化性能。同还可以调节基学习器(决策树)的参数。参数含义具体见 [sklearn 文档](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "742GAdwCfJku"
      },
      "source": [
        "## GBDT\n",
        "\n",
        "再来对比一下决策树的 boosting 版本 GBDT 的表现吧！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivZFBB2CfJku",
        "outputId": "d7853929-3cf7-4057-ff64-1aeac480b9ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(n_estimators=10)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gbc = GradientBoostingClassifier(n_estimators=10)\n",
        "gbc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_yRSc28fJkv",
        "outputId": "cf8bf89c-78eb-43c6-8c62-a5c40f165527"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8423"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gbc.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuxudT9FfJkv",
        "outputId": "72c4d920-09a7-44b9-822a-a9f37b6d5cd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.846"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gbc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G33NRN5fJkv"
      },
      "source": [
        "> 观察以上结果，虽然模型没有过拟合，但是可能出现了欠拟合，训练集的准确度远低于普通决策数和随机森林的准确度，此时最简单的方法就是增大 `n_estimators` 参数的值，也就是增加子学习器的数量，从 GBDT 的原理出发，增加子学习器的数量也就是对标签的参差进行更加精细化的拟合，从而解决欠拟合。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p1xGevofJkv",
        "outputId": "9949c5af-7299-468c-d56f-7e64f0db7509"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(n_estimators=30)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gbc = GradientBoostingClassifier(n_estimators=30)\n",
        "gbc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px2MFLWLfJkv",
        "outputId": "f8917ba2-28c4-4bc0-c667-30b3a5c733c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9074333333333333, 0.9057)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gbc.score(X_train, y_train), gbc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FEOIcYufJkv"
      },
      "source": [
        "> 意料之中，表现有较大提升，并且训练集的指标和测试集的基本保持一致，没有出现过拟合的情况，所以应该还可以继续尝试提高这个参数。一般在未出现过拟合的情况下，我们只需要考虑继续提升模型的复杂度就好，这是提升表现最快的方法。当模型复杂度提高到出现过拟合的情况，我们再考虑使用一些降低过拟合的方法。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xYKCucxfJkv"
      },
      "source": [
        "## Bagging\n",
        "\n",
        "前述的随机森林和 GBDT 都是以决策树为基学习器的集成学习算法，但是要注意的是集成学习并不是决策树的专属，任何其他的学习器都可以作为集成学习的基学习器，比如逻辑回归、支持向量机。\n",
        "\n",
        "\n",
        "Bagging 是“bootstrap aggregating”的缩写。这是一个元算法，它从初始数据集中获取 M 个子样本（有放回），并在这些子样本上训练预测模型。最终模型是通过平均所有子模型获得的，通常会产生更好的结果。该技术的主要优点是它结合了正则化，你所需要做的就是为基学习器选择良好的参数。\n",
        "\n",
        "下面使用 sklearn 提供的通用 api 构造集成学习算法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8JBdJ86fJkv",
        "outputId": "bc881667-3bcf-4096-9753-af01aa0e42ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_samples=0.5,\n",
              "                  n_estimators=20)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 仍然以决策树作为基学习器\n",
        "bgc = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.5, max_features=1.0, n_estimators=20)\n",
        "bgc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfEF1hfbfJkw",
        "outputId": "f6305ff6-f5bf-48a5-ab73-a88d7eed1f0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9937333333333334"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bgc.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPEFNuAdfJkw",
        "outputId": "97586754-e27b-4f58-8efa-bf27562ac89c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9497"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bgc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iRh3tV8fJkw"
      },
      "outputs": [],
      "source": [
        "# 以逻辑回归作为基学习器\n",
        "bgc = BaggingClassifier(LogisticRegression(max_iter=500), max_samples=0.5, max_features=1.0, n_estimators=20)\n",
        "bgc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neJP6IxcfJkw",
        "outputId": "129c5b5c-2177-438f-9185-14035d75f73d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.94235, 0.9229)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bgc.score(X_train, y_train), bgc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCyLFN0ofJkw"
      },
      "source": [
        "> 上面我们成功地使用了逻辑回归作为基学习器完成了集成学习。你们可以自己尝试仅使用逻辑回归进行训练，对比单模型的表现和 bagging 版本的逻辑回归"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8NdiSP_fJkw"
      },
      "source": [
        "## Boosting\n",
        "\n",
        "boosting 是指能够将弱学习器转换为强学习器的一系列算法。 boosting 的主要原理是将一系列弱学习器（仅比随机猜测好）。对于那些在训练前期而被错误分类的样本，boosting 算法会给予更大的重视。然后通过加权多数投票（分类）或加权和（回归）组合预测，以产生最终预测。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dmRR7z8fJkx",
        "outputId": "b5e26fa6-73e0-4cdb-b45e-8f75b7113546"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), learning_rate=0.01,\n",
              "                   n_estimators=10)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adc = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators=10, learning_rate=0.01)\n",
        "adc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_M44_QjfJkx",
        "outputId": "fcdc5863-3cd3-4eb2-bc53-6604a0774823"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adc.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV6mQPUpfJkx",
        "outputId": "450206de-6032-4fc6-94e1-7351e7dc4f2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8738"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "RuslIN7nfJkx",
        "outputId": "dac9dd3f-6ebe-417c-beec-26aeb7af5e9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/xuhp/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/xuhp/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/xuhp/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/xuhp/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/xuhp/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/xuhp/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/xuhp/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/xuhp/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/xuhp/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/Users/xuhp/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=LogisticRegression(), learning_rate=0.01,\n",
              "                   n_estimators=10)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adc = AdaBoostClassifier(LogisticRegression(), n_estimators=10, learning_rate=0.01)\n",
        "adc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWfQ_27TfJkx",
        "outputId": "e9b41c4a-b106-4b51-c240-105c37cea50b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9316833333333333, 0.9234)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adc.score(X_train, y_train), adc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1l5b961fJkx"
      },
      "source": [
        "> 对比决策树和逻辑回归的 boosting 集成版本可以发现，逻辑回归相对来说泛化能力更好，决策树更容易过拟合"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_M76rlQfJkx",
        "outputId": "58d31733-98a0-4c74-a203-2f3cfc6983ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(min_samples_leaf=8),\n",
              "                   learning_rate=0.01, n_estimators=10)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adc = AdaBoostClassifier(DecisionTreeClassifier(min_samples_leaf=8), n_estimators=10, learning_rate=0.01)\n",
        "adc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bg_tgCNpfJkx",
        "outputId": "38a3a92e-92f7-473d-e565-0a53cb28951a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.99825, 0.95)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adc.score(X_train, y_train), adc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8kM6ZmBfJkx"
      },
      "source": [
        "> 事实上过拟合并不是一件坏事，如果你的模型都无法过拟合的话说明它无法很好的拟合训练数据，所以决策树在一开始过拟合的很厉害这也说明他的潜力，可以看到上面经过参数的调节，决策树的 boosting 版本轻松地超过了逻辑回归的 boosting 版本"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "L4_Homework_Reference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}